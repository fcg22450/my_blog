<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Scraypè¯¦è§£ - Chevalier de bronze</title><link rel="manifest" href="/manifest.json"><meta name="theme-color" content="black"><meta name="application-name" content="Little Blog"><meta name="msapplication-TileImage" content="/img/favicon.png"><meta name="msapplication-TileColor" content="black"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Little Blog"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="scrapy:"><meta property="og:type" content="blog"><meta property="og:title" content="Scraypè¯¦è§£"><meta property="og:url" content="http://sokrates.com.cn/2022/11/30/Study-notes-Python-Spider-scrapy%E8%AF%A6%E8%A7%A3/"><meta property="og:site_name" content="Chevalier de bronze"><meta property="og:description" content="scrapy:"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="http://sokrates.com.cn/img/images/R-C.png"><meta property="article:published_time" content="2022-11-30T15:10:51.380Z"><meta property="article:modified_time" content="2022-11-29T08:23:32.857Z"><meta property="article:author" content="Kawakami Ari"><meta property="article:tag" content="Python"><meta property="article:tag" content="Spider"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/img/images/R-C.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://sokrates.com.cn/2022/11/30/Study-notes-Python-Spider-scrapy%E8%AF%A6%E8%A7%A3/"},"headline":"Scraypè¯¦è§£","image":["http://sokrates.com.cn/img/images/R-C.png"],"datePublished":"2022-11-30T15:10:51.380Z","dateModified":"2022-11-29T08:23:32.857Z","author":{"@type":"Person","name":"Kawakami Ari"},"publisher":{"@type":"Organization","name":"Chevalier de bronze","logo":{"@type":"ImageObject","url":"http://sokrates.com.cn/img/logo.png"}},"description":"scrapy:"}</script><link rel="canonical" href="http://sokrates.com.cn/2022/11/30/Study-notes-Python-Spider-scrapy%E8%AF%A6%E8%A7%A3/"><link rel="icon" href="/img/favicon.png"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Oxanium:wght@300;400;600&amp;family=Roboto+Mono"><link rel="stylesheet" href="/css/cyberpunk.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 5.4.0"></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.png" alt="Chevalier de bronze" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/kawakami-araki/kawakami-araki.github.io"><i class="fab fa-github"></i></a><a class="navbar-item search" title="æœç´¢" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><div class="card-image"><span class="image is-7by3"><img class="fill" src="/img/images/R-C.png" alt="Scraypè¯¦è§£"></span></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2022-11-30T15:10:51.380Z" title="2022/11/30 23:10:51">2022-11-30</time>å‘è¡¨</span><span class="level-item"><time dateTime="2022-11-29T08:23:32.857Z" title="2022/11/29 16:23:32">2022-11-29</time>æ›´æ–°</span><span class="level-item"><a class="link-muted" href="/categories/Python/">Python</a></span><span class="level-item">29 åˆ†é’Ÿè¯»å®Œ (å¤§çº¦4362ä¸ªå­—)</span></div></div><h1 class="title is-3 is-size-4-mobile">Scraypè¯¦è§£</h1><div class="content"><h1 id="scrapy"><a href="#scrapy" class="headerlink" title="scrapy:"></a>scrapy:</h1><span id="more"></span>
<ul>
<li><p>ä»€ä¹ˆæ˜¯æ¡†æ¶?</p>
<ul>
<li>ç»§æ‰¿äº†å„ç§åŠŸèƒ½ä¸”å…·æœ‰å¾ˆå¼ºé€šç”¨æ€§(å¯ä»¥è¢«åº”ç”¨åœ¨å„ç§ä¸åŒçš„éœ€æ±‚ä¸­)çš„ä¸€ä¸ªé¡¹ç›®æ¨¡æ¿</li>
<li>æˆ‘ä»¬éœ€è¦åšçš„å°±æ˜¯å­¦ä¹ æ€ä¹ˆä½¿ç”¨è¿™äº›æ¡†æ¶çš„åŠŸèƒ½</li>
</ul>
</li>
<li><p>scrapyæ¡†æ¶é›†æˆçš„åŠŸèƒ½æœ‰å“ªäº›?</p>
<ul>
<li>é«˜æ€§èƒ½çš„æ•°æ®è§£ææ“ä½œ</li>
<li>é«˜æ€§èƒ½çš„æ•°æ®ä¸‹è½½æ“ä½œ</li>
<li>æŒä¹…åŒ–æ•°æ®å­˜å‚¨</li>
</ul>
</li>
<li><p>scrapyé€šå¸¸åªç”¨äºgetè¯·æ±‚,å¹¶ä¸é€‚ç”¨äºpostè¯·æ±‚çš„æ¨¡æ‹Ÿç™»é™†</p>
</li>
<li><p>scrapyç¯å¢ƒå®‰è£…</p>
<ol>
<li>pip install wheel</li>
<li>pip install twisted<ul>
<li><a target="_blank" rel="noopener" href="https://pypi.org/project/Twisted/#files">twistedä¸‹è½½</a></li>
</ul>
</li>
<li>pip install pywin32</li>
<li>pip install scrapy</li>
</ol>
</li>
<li><p>å¼€å§‹åˆ›å»ºscrapyå·¥ç¨‹</p>
<ul>
<li>è¿›å…¥ç»ˆç«¯è¾“å…¥æŒ‡ä»¤åˆ›å»ºæ–°çš„scrapyå·¥ç¨‹</li>
<li>â€˜scrapy startproject projectnameâ€™</li>
<li>æŒ‰ç…§æŒ‡ä»¤åˆ›å»ºæ–°çš„çˆ¬è™«æ–‡ä»¶ </li>
<li>scrapy genspider spiderName <a target="_blank" rel="noopener" href="http://www.xxx.com/">www.xxx.com</a></li>
<li>å¯åŠ¨çˆ¬è™«ç¨‹åº<ul>
<li>scrapyçˆ¬è™«ä¸èƒ½ç›´æ¥è¿è¡Œ,</li>
<li>åœ¨å‘½ä»¤çª—å£ä¸­è¾“å…¥æŒ‡ä»¤</li>
<li>scrapy crawl spiderName<ul>
<li>scrapy crawl spiderName â€“nolog</li>
<li>è¿è¡Œæ—¶ä¸è¾“å‡ºæ—¥å¿—ä¿¡æ¯</li>
<li>åœ¨settingæ–‡ä»¶ä¸­æ·»åŠ é…ç½®</li>
<li>LOG_LEVEL= â€˜ERRORâ€™â€™</li>
<li>å½“å‘ç”Ÿé”™è¯¯æ—¶,å°†é”™è¯¯æ—¥å¿—è¾“å‡º,æ–¹ä¾¿è°ƒè¯•</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>scrapyå·¥ç¨‹è®¾ç½®â€“â€”â€“-setting</p>
<ul>
<li>User_Agent    è¿™é‡Œè®¾ç½®çš„æ˜¯çˆ¬è™«çš„è¯·æ±‚å¤´</li>
<li>ROBOTSTXT_OBEY = True   è¿™é‡Œè®¾ç½®çš„æ˜¯robotsåè®®,å½“å€¼ä¸ºTrueæ—¶,çˆ¬è™«å°†ä¼šåœ¨è¿è¡Œæ—¶ä¼˜å…ˆæŸ¥çœ‹robotsåè®®,å¦‚æœåè®®ä¸å…è®¸å°†ä¸ä¼šè¿›è¡Œçˆ¬å–</li>
</ul>
</li>
<li><p>scrapyå·¥ç¨‹ä½¿ç”¨</p>
<ul>
<li><p>æ„å»ºè§£æ</p>
</li>
<li><p>```python</p>
<h1 id="coding-utf-8"><a href="#coding-utf-8" class="headerlink" title="-- coding: utf-8 --"></a>-<em>- coding: utf-8 -</em>-</h1><p>import scrapy<br>class NewSpiderSpider(scrapy.Spider):</p>
<pre><code># çˆ¬è™«æ–‡ä»¶çš„åç§°,ç›¸å½“äºçˆ¬è™«æ–‡ä»¶çš„å”¯ä¸€æ ‡è¯†
name = &#39;ğŸ’€&#39;
# å¾ªåºçš„åŸŸå, é€šå¸¸æƒ…å†µä¸‹ä¸ä¼šä½¿ç”¨
# allowed_domains = [&#39;www.baidu.com&#39;]
# èµ·å§‹çš„urlåˆ—è¡¨, scrapyå°†ä¼šå¯¹åˆ—è¡¨ä¸­çš„urlè‡ªåŠ¨è¿›è¡Œè¯·æ±‚å‘é€
start_urls = [&#39;http://www.budejie.com/&#39;]

def parse(self, response):
    # åœ¨scrapyä¸­,æ•°æ®è§£æä¸éœ€è¦æ‰‹åŠ¨å¯¼å…¥etreeæ¥è¿›è¡Œ,ç›¸å¯¹çš„,è¿™é‡Œé¢é›†æˆäº†etree çš„åŠŸèƒ½,ä¹Ÿå°±æ˜¯è¯´,æˆ‘ä»¬å¯ä»¥ç›´æ¥ä½¿ç”¨scrapyçš„é›†æˆæ¥è¾¾åˆ°æˆ‘ä»¬è¿›è¡Œæ•°æ®è§£æçš„ç›®æ ‡
    # è¿™ä¸ªåŠŸèƒ½çš„ä½¿ç”¨æ–¹å¼å¦‚ä¸‹
    res = response.xpath(&#39;//div[@class=&quot;j-r-list-c-desc&quot;]/a/text()&#39;).extract()
    # extractæ–¹æ³•,æå–è·å–åˆ°çš„selectedå¯¹è±¡ä¸­çš„dataæ•°æ®,å½“å¯¹è±¡ä¸ºå•ä¸ªå¯¹è±¡çš„æ—¶å€™,è·å–åˆ°çš„å¯¹è±¡å°±æ˜¯å•ä¸ªçš„å­—ç¬¦ä¸²,
    # å½“æå–åˆ°çš„selectedå¯¹è±¡ä¸ºlistå¯¹è±¡æ—¶,è·å–åˆ°çš„æ•°æ®ä¹Ÿä¼šè‡ªåŠ¨å˜æˆä¸€ä¸ªåˆ—è¡¨,å¹¶ä¸éœ€è¦å¾ªç¯éå†selectedåˆ—è¡¨æ¥è¿›è¡Œæå–
    for i in res:
        print(i)
</code></pre>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">- scrapyæŒä¹…åŒ–å­˜å‚¨</span><br><span class="line"></span><br><span class="line">  - åŸºäºç»ˆç«¯çª—å£çš„æŒä¹…åŒ–å­˜å‚¨</span><br><span class="line"></span><br><span class="line">    - ç‰¹æ€§:åªå¯ä»¥å°†parseæ–¹æ³•çš„è¿”å›å€¼å†™å…¥åˆ°æœ¬åœ°çš„ç£ç›˜æ–‡ä»¶ä¸­</span><br><span class="line"></span><br><span class="line">    - æŒ‡ä»¤: scrapy crawl spiderName -o filePath</span><br><span class="line"></span><br><span class="line">    - ```python</span><br><span class="line">          def parse(self, response):</span><br><span class="line">              li_list = response.xpath(&#x27;//div[@class=&quot;j-r-list&quot;]/ul/li&#x27;)</span><br><span class="line">              all_data = []</span><br><span class="line">              for li in li_list:</span><br><span class="line">                  author = li.xpath(&#x27;./div[1]/div[2]/a/text()&#x27;).extract()[0]</span><br><span class="line">                  content = li.xpath(&#x27;./div[2]/div[1]/a/text()&#x27;).extract()[0]</span><br><span class="line">                  dic = &#123;</span><br><span class="line">                      &#x27;Author&#x27;: author,</span><br><span class="line">                      &#x27;Content&#x27;: content</span><br><span class="line">                  &#125;</span><br><span class="line">                  all_data.append(dic)</span><br><span class="line">              return all_data</span><br><span class="line">      # scrapy å°†ä¼šå¯¹parseçš„è¿”å›å€¼è¿›è¡Œå¤„ç†,å¹¶é¢„ç½®äº†å†…éƒ¨çš„æŒä¹…åŒ–å­˜å‚¨æ¨¡å—.è¿™ä¸ªæŒä¹…åŒ–å­˜å‚¨åŸºäºå‘½ä»¤ç»ˆç«¯è¿è¡Œ,è¯¥é€‰é¡¹ä¸æ”¯æŒtxtæ–‡ä»¶å­˜å‚¨,ç›®å‰ä»…æ”¯æŒ(&#x27;json&#x27;, &#x27;jsonlines&#x27;, &#x27;jl&#x27;, &#x27;csv&#x27;, &#x27;xml&#x27;, &#x27;marshal&#x27;, &#x27;pickle&#x27;)è¿™ä¸ƒç§æ–‡ä»¶</span><br></pre></td></tr></table></figure>

<p>- </p>
</li>
<li><p>åŸºäºç®¡é“çš„æŒä¹…åŒ–å­˜å‚¨</p>
<ul>
<li><p>ç®¡é“è¯å­˜å‚¨éœ€è¦ä½¿ç”¨scrapyä¸­å°å­˜çš„ä¸€äº›æ–¹æ³•,åŒæ—¶éœ€è¦è¿›è¡Œä¸€äº›å¤„ç†,è¿™æ ·çš„å­˜å‚¨æ–¹å¼æ”¯æŒtxtæ–‡æ¡£å­˜å‚¨</p>
</li>
<li><p>ç®¡é“æ–‡ä»¶å­˜å‚¨ç¤ºä¾‹:</p>
</li>
<li><p>```python<br>class FirstblodPipeline(object):</p>
<pre><code>fp = None
# è®¾å®šåœ¨ç®¡é“è¿è¡Œå¼€å§‹ä¹‹å‰ä¼˜å…ˆè¿è¡Œçš„ä»£ç 
def open_spider(self, spider):
    print(&#39;çˆ¬è™«å¼€å§‹è¿è¡Œ~~~~~~~&#39;)
    # é€šè¿‡åœ¨ç®¡é“è¿è¡Œå¼€å§‹ä¹‹å‰æ‰“å¼€æ–‡ä»¶çš„å½¢å¼æ¥ç¡®ä¿è¿™ä¸ªæ–‡ä»¶æ¯æ¬¡åªéœ€è¦æ‰“å¼€ä¸€æ¬¡
    self.fp = open(&#39;./firstBlod/spiders/all_data.txt&#39;, &#39;w&#39;, encoding=&#39;utf-8&#39;)

# å½“æ•°æ®è¢«æäº¤æ—¶æ‰§è¡Œçš„ä»£ç ,åœ¨è¿™é‡Œè¿›è¡Œæ•°æ®æŒä¹…åŒ–å­˜å‚¨
def process_item(self, item, spider):
    author = item[&#39;author&#39;]
    content = item[&#39;content&#39;]
    # è°ƒç”¨å·²ç»æ‰“å¼€çš„æ–‡ä»¶,å¹¶åœ¨é‡Œé¢è¿›è¡Œå†™å…¥æ“ä½œ
    self.fp.write(author + &#39;:&#39; + content + &#39;\n&#39;)
    # å°†itemè½¬äº¤ç»™ä¸‹ä¸€ä¸ªç®¡é“ç±»
    return item
# å½“ç®¡é“å…³é—­æ—¶æ‰§è¡Œçš„ä»£ç 
def close_spider(self, spider):
    print(&#39;çˆ¬è™«ç»“æŸè¿è¡Œ~~~~~~~&#39;)
    # åœ¨ä»£ç æ•´ä½“è¿è¡Œç»“æŸçš„æ—¶å€™,å…³é—­æ‰“å¼€çš„æ–‡ä»¶
    self.fp.close()
</code></pre>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">- itemæ–‡ä»¶å¯¹è±¡å®ä¾‹</span><br><span class="line"></span><br><span class="line">- ```python</span><br><span class="line">  class FirstblodItem(scrapy.Item):</span><br><span class="line">      # define the fields for your item here like:</span><br><span class="line">      # name = scrapy.Field()</span><br><span class="line">      # æ„å»ºæ–°çš„itemå¯¹è±¡ä¸­çš„å‚æ•°</span><br><span class="line">      # æ ¼å¼ä¸º    name = scrapy.Field()</span><br><span class="line">      # ä½¿ç”¨fieldæ–‡ä»¶æ ¼å¼çš„æ—¶å€™,å…¼å®¹å‡ ä¹æ‰€æœ‰çš„æ–‡ä»¶ç±»å‹</span><br><span class="line">      # åŒ…æ‹¬ä½†ä¸ä»…é™äº   åˆ—è¡¨,å…ƒç»„,å­—å…¸,å­—ç¬¦ä¸²,æ•°å­—,äºŒè¿›åˆ¶æµç­‰å„ç§å„æ ·çš„å½¢å¼</span><br><span class="line">      author = scrapy.Field()</span><br><span class="line">      content = scrapy.Field()</span><br></pre></td></tr></table></figure></li>
<li><p>settingsæ–‡ä»¶å®ä¾‹</p>
</li>
<li><p>```python</p>
<h1 id="Configure-item-pipelines"><a href="#Configure-item-pipelines" class="headerlink" title="Configure item pipelines"></a>Configure item pipelines</h1><h1 id="See-https-docs-scrapy-org-en-latest-topics-item-pipeline-html"><a href="#See-https-docs-scrapy-org-en-latest-topics-item-pipeline-html" class="headerlink" title="See https://docs.scrapy.org/en/latest/topics/item-pipeline.html"></a>See <a target="_blank" rel="noopener" href="https://docs.scrapy.org/en/latest/topics/item-pipeline.html">https://docs.scrapy.org/en/latest/topics/item-pipeline.html</a></h1><p>ITEM_PIPELINES = {<br>   â€˜firstBlod.pipelines.FirstblodPipelineâ€™: 300,</p>
<pre><code># ç®¡é“å¯¹è±¡çš„åå­—,åé¢çš„æ•°å€¼ä¸ºç®¡é“ä¼˜å…ˆå€¼
# ä¼˜å…ˆå€¼é«˜çš„å°†ä¼šä¼˜å…ˆæ‰§è¡Œ
# æ•°å€¼è¶Šä½ä¼˜å…ˆå€¼è¶Šé«˜
</code></pre>
<p>}</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">- æ‰¾åˆ°ç®¡é“ç›¸å…³ä»£ç è¿›è¡Œæ¿€æ´»</span><br><span class="line"></span><br><span class="line">- åœ¨çˆ¬è™«æ–‡ä»¶ä¸­è¿›è¡Œä½¿ç”¨</span><br><span class="line"></span><br><span class="line">- ```python</span><br><span class="line">  import scrapy</span><br><span class="line">  from firstBlod.items import FirstblodItem</span><br><span class="line">  # å¯¼å…¥itemè®¾å®šç±»</span><br><span class="line">  class NewSpiderSpider(scrapy.Spider):</span><br><span class="line">      name = &#x27;ğŸ’€&#x27;</span><br><span class="line">      start_urls = [&#x27;http://www.budejie.com/&#x27;]</span><br><span class="line">  </span><br><span class="line">      def parse(self, response):</span><br><span class="line">          li_list = response.xpath(&#x27;//div[@class=&quot;j-r-list&quot;]/ul/li&#x27;)</span><br><span class="line">          # all_data = []</span><br><span class="line">          for li in li_list:</span><br><span class="line">              author = li.xpath(&#x27;./div[1]/div[2]/a/text()&#x27;).extract()[0]</span><br><span class="line">              content = li.xpath(&#x27;./div[2]/div[1]/a/text()&#x27;).extract()[0]</span><br><span class="line">              item = FirstblodItem()</span><br><span class="line">              # å®ä¾‹åŒ–itemå¯¹è±¡</span><br><span class="line">              item[&#x27;author&#x27;] = author</span><br><span class="line">              item[&#x27;content&#x27;] = content</span><br><span class="line">              # itemä½¿ç”¨æ–¹æ³•å’Œå­—å…¸ç±»ä¼¼</span><br><span class="line">              # ä½¿ç”¨yieldæ–¹æ³•è¿”å›å°è£…å®Œæˆçš„itemå¯¹è±¡</span><br><span class="line">              # å½“ä½¿ç”¨yieldè¿”å›çš„æ—¶å€™,å°†ä¼šè‡ªåŠ¨å°†itemä¼ è¾“åˆ°ç®¡é“å¯¹åº”çš„æ¥å—ç±»ä¸­,è¿›è¡Œå¤„ç†å¹¶æŒä¹…åŒ–å­˜å‚¨</span><br><span class="line">              yield item</span><br></pre></td></tr></table></figure></li>
<li><p>å°†ä¸Šè¿°æ¡ä»¶å‡†å¤‡å®Œæ¯•ä¹‹å,å°±å¯ä»¥è¿›è¡Œæ•°æ®çš„æŒä¹…åŒ–å­˜å‚¨äº†</p>
</li>
<li><p>å½“ç„¶,ä¹Ÿä¸ä¸€å®šéè¦å­˜å‚¨åˆ°æ–‡ä»¶ä¸­å»,æ¯•ç«Ÿè¿˜æœ‰ä¸€äº›æ¶‰åŠåˆ°æ•°æ®åº“çš„å­˜å‚¨,éƒ½å¯ä»¥æ”¾åˆ°è¿™ä¸ªç®¡é“ä¸­æ¥è¿›è¡Œ</p>
</li>
<li><p>ä¹Ÿå°±æ˜¯,ç®¡é“æ–‡ä»¶ä¸­çš„ä¸€ä¸ªç®¡é“ç±»è´Ÿè´£ä¸€ç§æŒä¹…åŒ–å­˜å‚¨çš„æ–¹æ¡ˆ</p>
</li>
<li><p>itemæäº¤çš„æ—¶å€™å°†ä¼šæŠŠitemäº¤ç»™ä¼˜å…ˆçº§æœ€é«˜çš„ç®¡é“ç±»</p>
</li>
<li><p>åœ¨ç®¡é“ç±»ä¸­,return itemçš„ä½œç”¨æ˜¯å°†itemè½¬äº¤ç»™ä¸‹ä¸€ä¸ªç®¡é“ç±»</p>
</li>
<li><p>åŒç®¡é“ç±»å†™æ³•ä»¥åŠMysqlæ•°æ®åº“å†™å…¥</p>
</li>
<li><p>```python<br>class MysqlPip(object):</p>
<pre><code>conn = None
cursor = None

# è®¾å®šåœ¨ç®¡é“è¿è¡Œå¼€å§‹ä¹‹å‰ä¼˜å…ˆè¿è¡Œçš„ä»£ç 
def open_spider(self, spider):
    # é€šè¿‡åœ¨ç®¡é“è¿è¡Œå¼€å§‹ä¹‹å‰æ‰“å¼€æ–‡ä»¶çš„å½¢å¼æ¥ç¡®ä¿è¿™ä¸ªæ–‡ä»¶æ¯æ¬¡åªéœ€è¦æ‰“å¼€ä¸€æ¬¡
    print(&#39;çˆ¬è™«2å¼€å§‹è¿è¡Œ~~~~~~~&#39;)
    # å»ºç«‹æ•°æ®åº“æ¸¸æ ‡
    self.conn = pymysql.Connect(host=&#39;127.0.0.1&#39;,port=3306,user=&#39;root&#39;,password=&#39;000000&#39;,db=&#39;spider&#39;,charset=&#39;utf8&#39;)
    print(self.conn)
# å½“æ•°æ®è¢«æäº¤æ—¶æ‰§è¡Œçš„ä»£ç ,åœ¨è¿™é‡Œè¿›è¡Œæ•°æ®æŒä¹…åŒ–å­˜å‚¨
def process_item(self, item, spider):
    author = item[&#39;author&#39;]
    content = item[&#39;content&#39;]
    sql = &#39;insert into bs values (&quot;%s&quot;,&quot;%s&quot;)&#39;% (author,content)
    print(sql)
    self.cursor = self.conn.cursor()
    try:
        self.cursor.execute(sql)
        self.conn.commit()
    except Exception as e:
        print(e)
        self.conn.rollback()
    print(&#39;----------------------------------------------------------------------------&#39;)
    return item
def close_spider(self, spider):
    print(&#39;çˆ¬è™«2ç»“æŸè¿è¡Œ~~~~~~~&#39;)
    self.cursor.close()
    self.conn.close()
</code></pre>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">- æ‰‹åŠ¨å‘é€è¯·æ±‚:</span><br><span class="line"></span><br><span class="line">  - æ‰‹åŠ¨å‘é€getè¯·æ±‚</span><br><span class="line"></span><br><span class="line">    - åº”ç”¨åœºæ™¯:   è¯·æ±‚åŒä¸€ä¸ªä¸»é¡µé¢ä¸‹çš„å¤šä¸ªé¡µé¢</span><br><span class="line"></span><br><span class="line">    - ä»£ç </span><br><span class="line"></span><br><span class="line">      ```python</span><br><span class="line">      # -*- coding: utf-8 -*-</span><br><span class="line">      import scrapy</span><br><span class="line">      from firstBlod.items import FirstblodItem</span><br><span class="line">      </span><br><span class="line">      class NewSpiderSpider(scrapy.Spider):</span><br><span class="line">          # çˆ¬è™«æ–‡ä»¶çš„åç§°,ç›¸å½“äºçˆ¬è™«æ–‡ä»¶çš„å”¯ä¸€æ ‡è¯†</span><br><span class="line">          name = &#x27;new_spider&#x27;</span><br><span class="line">          # å¾ªåºçš„åŸŸå, é€šå¸¸æƒ…å†µä¸‹ä¸ä¼šä½¿ç”¨</span><br><span class="line">          # allowed_domains = [&#x27;www.baidu.com&#x27;]</span><br><span class="line">          # èµ·å§‹çš„urlåˆ—è¡¨, scrapyå°†ä¼šå¯¹åˆ—è¡¨ä¸­çš„urlè‡ªåŠ¨è¿›è¡Œè¯·æ±‚å‘é€</span><br><span class="line">          start_urls = [</span><br><span class="line">              &#x27;https://www.zhipin.com/job_detail/?query=python&amp;city=101010100&amp;industry=&amp;position=&#x27;,</span><br><span class="line">              ]</span><br><span class="line">          # è®¾ç½®åŸºæœ¬çš„urlæ¨¡æ¿</span><br><span class="line">          url = &#x27;https://www.zhipin.com/c101010100/?query=python&amp;page=%d&amp;ka=page-%d&#x27;</span><br><span class="line">          # è®°å½•é¡µæ•°</span><br><span class="line">          page_name = 1</span><br><span class="line">      </span><br><span class="line">          def parse(self, response):</span><br><span class="line">              li_list = response.xpath(&#x27;//div[@class=&quot;job-list&quot;]&#x27;)</span><br><span class="line">              print(li_list)</span><br><span class="line">              # all_data = []</span><br><span class="line">              for li in li_list:</span><br><span class="line">                  # èŒä½åç§°</span><br><span class="line">                  Job_title = li.xpath(&#x27;./div/div[1]/h3/a/div[1]/text()&#x27;).extract()[0]</span><br><span class="line">                  # å…¬å¸åç§°</span><br><span class="line">                  Corporate_name = li.xpath(&#x27;./div/div[1]/a/text()&#x27;).extract()[0]</span><br><span class="line">                  # åœ°å€</span><br><span class="line">                  all_address = li.xpath(&#x27;./div/div[1]/p//text()&#x27;).extract()[0]</span><br><span class="line">                  # ç»éªŒ experience</span><br><span class="line">                  # address,experience,Education = all_address.split(&#x27;|&#x27;)</span><br><span class="line">                  #å­¦å† Education</span><br><span class="line">                  # dic = &#123;</span><br><span class="line">                  #     &#x27;Author&#x27;: author,</span><br><span class="line">                  #     &#x27;Content&#x27;: content</span><br><span class="line">                  # &#125;</span><br><span class="line">                  # all_data.append(dic)</span><br><span class="line">                  item = FirstblodItem()</span><br><span class="line">                  item[&#x27;Job_title&#x27;] = Job_title</span><br><span class="line">                  item[&#x27;Corporate_name&#x27;] = Corporate_name</span><br><span class="line">                  yield item</span><br><span class="line">              # ç¡®å®šå½“å‰é¡µæ•°,</span><br><span class="line">              if self.page_name &lt;= 5:</span><br><span class="line">                  self.page_name += 1</span><br><span class="line">                  # æ‹¼æ¥æ–°çš„url</span><br><span class="line">                  new_url = format(self.url%(self.page_name,self.page_name))</span><br><span class="line">                  # ä½¿ç”¨yieldè¿›è¡Œè¯·æ±‚,å‚æ•°callbackä¸ºå¤„ç†è¿™äº›é¡µé¢ä¿¡æ¯æ‰€ç”¨çš„å‡½æ•°,å¯è‡ªè¡Œè®¾å®š,ä¹Ÿå¯ç”¨é€’å½’çš„æ–¹å¼ä½¿ç”¨å½“å‰çš„å‡½æ•°</span><br><span class="line">                  yield scrapy.Request(new_url,callback=self.parse)</span><br><span class="line">              else:</span><br><span class="line">                  return li_list</span><br></pre></td></tr></table></figure>

<ul>
<li><p>é‡å†™çˆ¶ç±»çš„è‡ªåŠ¨è¯·æ±‚æ–¹æ³•</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># é‡å†™çˆ¶ç±»æ–¹æ³•æ„å‘³ç€æˆ‘ä»¬å¯ä»¥è‡ªå®šä¹‰æ•°æ®æ¸…æ´—å‡½æ•°,è€Œä¸éœ€è¦å±€é™äºparse</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">start_requests</span>(<span class="params">self</span>):</span></span><br><span class="line">	<span class="keyword">for</span> url <span class="keyword">in</span> self.start_urls:</span><br><span class="line">		<span class="keyword">yield</span> scrapy.Request(url,callback=self.parse)</span><br></pre></td></tr></table></figure></li>
<li><p>è¦æƒ³ä½¿scrapyè‡ªåŠ¨å‘é€getè¯·æ±‚,éœ€è¦é‡å†™start_requestsæ–¹æ³•</p>
</li>
</ul>
</li>
</ul>
<h2 id="scrapyå›¾ç‰‡å¤„ç†"><a href="#scrapyå›¾ç‰‡å¤„ç†" class="headerlink" title="scrapyå›¾ç‰‡å¤„ç†:"></a>scrapyå›¾ç‰‡å¤„ç†:</h2></li>
</ul>
<ol>
<li><p>åœ¨scrapyä¸­,æœ‰ç€ä¸“é—¨çš„æ¨¡å—å¯¹å›¾ç‰‡æ•°æ®è¿›è¡Œè¯·æ±‚ä»¥åŠå¤„ç†,æˆ‘ä»¬åªéœ€è¦å°†è·å–åˆ°çš„å›¾ç‰‡urlä»¥itemçš„å½¢å¼ä¼ è¾“åˆ°æˆ‘ä»¬çš„ç®¡é“ä¹‹ä¸­è¿›è¡Œå¤„ç†å³å¯,itemå¯¹è±¡çš„åˆ›å»ºäºå¯»å¸¸çš„åˆ›å»ºæ–¹æ³•æ²¡è®¾ä¹ˆåŒºåˆ«,scrapy.FieldsåŒ…å®¹æ€§æå¼º,ä¸éœ€è¦è€ƒè™‘å…¼å®¹æ€§é—®é¢˜,</p>
</li>
<li><p>åœ¨æäº¤åˆ°ç®¡é“ä¸­å»ä¹‹å,æˆ‘ä»¬å¯ä»¥åœ¨ç®¡é“ä¹‹ä¸­å¯¹itemä¸­çš„æ•°æ®è¿›è¡Œå¤„ç†,</p>
</li>
<li><p>ä½¿ç”¨scrapyä¸­å°è£…çš„å›¾ç‰‡å¤„ç†ä¸“ç”¨ç±»scrapy.pipelines.images import ImagePipeline</p>
</li>
<li><p>åˆ›å»ºä¸€ä¸ªæ–°çš„ç®¡é“ç±»,è¿™ä¸ªç®¡é“ç±»ç»§æ‰¿è‡ªImagePipline</p>
</li>
<li><p>```python<br>class ImgSpidersPipeline(ImagesPipeline):</p>
<pre><code># å¯¹ä¸€ä¸ªå›¾ç‰‡é“¾æ¥è¿›è¡Œè¯·æ±‚å‘é€
# item å°±æ˜¯scrapyæäº¤è¿‡æ¥çš„itemæ•°æ®
def get_media_requests(self, item, info):
    yield scrapy.Request(item[&#39;src&#39;])

# å‡†å¤‡æ–‡ä»¶å
def file_path(self, request, response=None, info=None):
    file_name = request.url.split(&#39;/&#39;)[-1]
    print(&#39;æ­£åœ¨ä¸‹è½½&#39;,file_name,&#39;............&#39;)
    return file_name
# å°†itemä¼ é€’ç»™ä¸‹ä¸€ä¸ªå³å°†æ‰§è¡Œçš„ç®¡é“ç±»
def item_completed(self, results, item, info):
    return item
</code></pre>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">6. å®Œæˆè¿™äº›ä¹‹å,æˆ‘ä»¬è¿˜éœ€è¦å¯¹å›¾ç‰‡çš„å­˜å‚¨è·¯å¾„è¿›è¡Œè®¾ç½®,åœ¨settingæ–‡ä»¶ä¸­æ·»åŠ æ–°çš„å±æ€§</span><br><span class="line"></span><br><span class="line">   - IMAGES_STORE = â€œimagePathâ€</span><br><span class="line"></span><br><span class="line">   - imagePathè‡ªè¡Œè®¾ç½®,æœ€å¥½è®¾ç½®ä¸ºç»å¯¹è·¯å¾„,å¦‚æœä½¿ç”¨ç›¸å¯¹è·¯å¾„çš„è¯,æœ€å¥½å‚è€ƒdjangoä¸­çš„æ–‡ä»¶è·¯å¾„çš„å†™æ³•,å…ˆç¡®å®šå·¥ç¨‹çš„è·¯å¾„,ç„¶åå†åœ¨å·¥ç¨‹è·¯å¾„çš„åŸºç¡€ä¸Šè®¾å®šç›¸å¯¹è·¯å¾„</span><br><span class="line"></span><br><span class="line">   - djangoæ–¹æ³•è®¾ç½®è·¯å¾„å¦‚ä¸‹:</span><br><span class="line"></span><br><span class="line">   - ```python</span><br><span class="line">     import os</span><br><span class="line">     # è·å–å½“å‰æ–‡ä»¶å¤¹çš„ä¸»è·¯å¾„</span><br><span class="line">     BASE_DIR = os.path.dirname(os.path.abspath(__file__))</span><br><span class="line">     # å°†è¦æ·»åŠ çš„å›¾ç‰‡æ–‡ä»¶ä¿å­˜è·¯å¾„åŠ å…¥åˆ°ä¸»è·¯å¾„ä¸­å»</span><br><span class="line">     IMAGES_STORE = os.path.join(BASE_DIR,&#x27;imgsLib&#x27;)</span><br></pre></td></tr></table></figure>

<ul>
<li>è¿™ä¸ªæ–¹æ³•åŒæ ·è®¾ç½®åœ¨settingsæ–‡ä»¶ä¸­</li>
</ul>
</li>
<li><p>å®Œæˆè¿™äº›ä¹‹å,åªéœ€è¦åœ¨settingsä¸­å°†å†™å¥½çš„ç®¡é“ç±»è¿›è¡Œæ³¨å†Œ,å³å¯å¼€å§‹è¿™ä¸ªç®¡é“ç±»</p>
</li>
<li><p>è¿è¡Œçˆ¬è™«ç¨‹åº,å°†ä¼šå¼€å§‹å…¨è‡ªåŠ¨ä¸‹è½½é€‰ä¸­çš„å›¾ç‰‡,æ ¹æ®ä¹‹å‰å­¦è¿‡çš„æ–¹æ³•,å³è®¾å®šç½‘å€çš„åŸºç¡€æ¨¡æ¿,å³å¯å®ç°å›¾ç‰‡çš„æ‰¹é‡ä¸‹è½½</p>
</li>
</ol>
</li>
</ul>
<h2 id="å¦‚ä½•æé«˜scrapyçˆ¬è™«çš„æ•ˆç‡"><a href="#å¦‚ä½•æé«˜scrapyçˆ¬è™«çš„æ•ˆç‡" class="headerlink" title="å¦‚ä½•æé«˜scrapyçˆ¬è™«çš„æ•ˆç‡"></a>å¦‚ä½•æé«˜scrapyçˆ¬è™«çš„æ•ˆç‡</h2><ol>
<li>å¢åŠ å¹¶å‘æ•°é‡<ul>
<li>CONCURRENT_REQUESTS = 32</li>
<li>é»˜è®¤å¹¶å‘æ•°é‡ä¸º32</li>
<li>å¯ä»¥è‡ªè¡Œè®¾ç½®</li>
</ul>
</li>
<li>é™ä½æ—¥å¿—ç­‰çº§<ul>
<li>LOG_LEVEL = â€œINFOâ€</li>
<li>LOG_LEVEL = â€œERRORâ€</li>
</ul>
</li>
<li>ç¦æ­¢cookie<ul>
<li>COOKIES_ENABLED = False</li>
<li>åœ¨scrapyä¸­ä¼šè‡ªåŠ¨å¯¹cookieè¿›è¡Œå¤„ç†,ä¸ç®¡è¿™ä¸ªé¡µé¢æ˜¯å¦éœ€è¦éªŒè¯cookie</li>
<li>å°†cookieå¤„ç†æ¨¡å—è¿›è¡Œå…³é—­,å°†ä¼šæå‡scrapyçš„æ‰§è¡Œæ•ˆç‡</li>
</ul>
</li>
<li>ç¦æ­¢é‡è¯•<ul>
<li>scrapyå°†ä¼šè‡ªåŠ¨å¯¹å¤±è´¥çš„è¯·æ±‚è¿›è¡Œé‡è¯•,è¿™ä¸¥é‡å½±å“åˆ°äº†çˆ¬è™«çš„æ‰§è¡Œæ•ˆç‡,å¯ä»¥å°†é‡è¯•åŠŸèƒ½ç¦æ‰,ä»è€Œæå‡æ‰§è¡Œæ•ˆç‡</li>
<li>åœ¨settingsæ–‡ä»¶ä¸­ä¹¦å†™ä»£ç </li>
<li>RETRY_ENABLED = False</li>
<li>å½“è¯·æ±‚å¤±è´¥çš„æ—¶å€™,scrapyå°†ä¸ä¼šå»å¤„ç†è¯·æ±‚å¤±è´¥çš„æ•°æ®,è€Œæ˜¯ä¼šç›´æ¥è·³è¿‡è¿›è¡Œä¸‹ä¸€æ¡</li>
</ul>
</li>
<li>å‡å°‘ä¸‹è½½è¶…æ—¶<ul>
<li>DOWNLOAD_TIMEOUT = 10</li>
<li>å†™å…¥è¿™æ®µä»£ç ,ä½œç”¨æ˜¯è®¾å®šè¯·æ±‚è¶…æ—¶çš„æ—¶é—´,ä¹Ÿå°±æ˜¯è¯´,å½“ä½ åœ¨äº²æ±‚æ—¶é—´è¶…è¿‡äº†åç§’çš„æ—¶å€™ä¾ç„¶æ²¡æœ‰æ‹¿åˆ°æ•°æ®çš„è¯,å°†ä¼šç»“æŸè¯·æ±‚,æ‰§è¡Œä¸‹ä¸€é¡¹,è€Œä¸æ˜¯ä¸€ç›´ç­‰å¾…ä¸‹å»,è¿™ä¸ªç†ŸçŸ¥çš„å•ä½æ˜¯ç§’<h2 id="è¯·æ±‚ä¼ å‚"><a href="#è¯·æ±‚ä¼ å‚" class="headerlink" title="è¯·æ±‚ä¼ å‚:"></a>è¯·æ±‚ä¼ å‚:</h2></li>
</ul>
</li>
</ol>
<ul>
<li>åŸºäºè¯·æ±‚ä¼ å‚å¯ä»¥å®ç°æ·±åº¦çˆ¬å–<ul>
<li>è¯·æ±‚ä¼ å‚,åœ¨è¿›è¡Œscrapy.Requestè¯·æ±‚çš„æ—¶å€™,å¯ä»¥ä½¿ç”¨ç¬¬ä¸‰ä¸ªå‚æ•°meta</li>
<li>è¿™ä¸ªå‚æ•°çš„ä½œç”¨æ˜¯å‘ä¸Šä¸€ä¸ªå‚æ•°callbackè¿™ä¸ªè§£æå‡½æ•°ä¸­ä¼ é€’å‚æ•°,å¥¹çš„æ•°æ®ç±»å‹æ˜¯ä¸€ä¸ªå­—å…¸,é€šè¿‡é”®å€¼å¯¹çš„å½¢å¼å­˜å‚¨éœ€è¦ä¼ é€’çš„æ•°æ®</li>
<li>å½“æˆ‘ä»¬éœ€è¦å°†ä¸Šä¸€ä¸ªè§£æå‡½æ•°ä¸­å®ä¾‹åŒ–å¥½çš„itemå¯¹è±¡ä¼ é€’åˆ°ä¸‹ä¸€ä¸ªè§£æå‡½æ•°ä¸­çš„æ—¶å€™,å¯ä»¥ä½¿ç”¨è¿™ä¸ªæ–¹æ³•è¿›è¡Œä¼ é€’</li>
<li>åœ¨å¦ä¸€ä¸ªè§£æå‡½æ•° ä¸­,é€šè¿‡responseå‚æ•°çš„metaå±æ€§å¯ä»¥æ‹¿åˆ°å‚æ•°çš„å†…å®¹å¹¶è¿›è¡Œæå–,è¿™ä¸ªå°±å¯ä»¥æ‹¿åˆ°ä¸Šä¸€ä¸ªå‡½æ•°ä¸­ä¼ é€’è¿‡æ¥çš„itemå¯¹è±¡,å®ç°ä¸åŒè§£æå‡½æ•°ä¹‹é—´çš„è¯·æ±‚ä¼ é€’</li>
<li>é€šè¿‡è¿™ä¸ªæ–¹å¼å¯ä»¥å®ç°æ·±åº¦çˆ¬å–,å³</li>
<li>å½“ä¸€æ•´å¥—æ•°æ®çš„å†…å®¹å¦‚æ ‡é¢˜å’Œç®€ä»‹å­˜åœ¨äºä¸¤ä¸ªå…³è”çš„é¡µé¢ä¸­,é‚£ä¹ˆæˆ‘ä»¬æƒ³è¦åŒæ—¶è·å¾—æ ‡é¢˜å’Œç®€ä»‹,å°±éœ€è¦è¿›è¡Œæ·±åº¦çˆ¬å–,ä½¿ç”¨è¿™ä¸ªæ–¹å¼ä¼ é€’çš„è¯,å°†ä¼šæ›´ç®€ä¾¿çš„å®ç°æ·±åº¦çˆ¬å–çš„è¦æ±‚</li>
</ul>
</li>
</ul>
<h2 id="ä¸­é—´ä»¶"><a href="#ä¸­é—´ä»¶" class="headerlink" title="ä¸­é—´ä»¶:"></a>ä¸­é—´ä»¶:</h2><p>åœ¨åˆ›å»ºå¥½çš„scrapyå·¥ç¨‹ä¸­,è‡ªå¸¦äº†ä¸¤ä¸ªåŸºç¡€çš„ä¸­é—´ä»¶</p>
<p>çˆ¬è™«ä¸­é—´ä»¶TwoSpidersSpiderMiddleware</p>
<p>ä¸‹è½½ä¸­é—´ä»¶TwoSpidersDownloaderMiddleware</p>
<ol>
<li><h3 id="æ‹¦æˆªä¸­é—´ä»¶"><a href="#æ‹¦æˆªä¸­é—´ä»¶" class="headerlink" title="æ‹¦æˆªä¸­é—´ä»¶"></a>æ‹¦æˆªä¸­é—´ä»¶</h3><ol>
<li><p>ä½œç”¨:æ‰¹é‡æ‹¦æˆªè¯·æ±‚</p>
</li>
<li><p>æ‹¦æˆªè¯·æ±‚:</p>
<ul>
<li><p>UAä¼ªè£…</p>
<ul>
<li>ç›®çš„:å°†æ‰€æœ‰çš„è¯·æ±‚çš„è¯·æ±‚å¤´å°½å¯èƒ½å¤šçš„ä¸åŒçš„è¯·æ±‚è½½ä½“æ ‡è¯†</li>
</ul>
</li>
<li><p>ä»£ç†æ“ä½œ</p>
<ul>
<li>```python<pre><code>def process_exception(self, request, exception, spider):
    # åœ¨é”™è¯¯æ•è·é˜¶æ®µè¿›è¡Œä»£ç†ä¿®æ­£,
    if request.url.split(&#39;:&#39;)[0] == &#39;http&#39;:
        request.meta[&#39;proxy&#39;] = &#39;http://&#39; + random.choice(PROXY_http)
    else:
        request.meta[&#39;proxy&#39;] = &#39;http://&#39; + random.choice(PROXY_https)
    return request
</code></pre>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">- ```python</span><br><span class="line">      def process_request(self, request, spider):</span><br><span class="line">          # å®ç°å°†æ‹¦æˆªåˆ°çš„requestè¯·æ±‚å°½å¯èƒ½å¤šçš„è®¾å®šæˆä¸åŒçš„è¯·æ±‚è½½ä½“èº«ä»½æ ‡è¯†</span><br><span class="line">          request.headers[&#x27;User-Agent&#x27;] = random.choice(user_agent_list)</span><br><span class="line">          # åœ¨æ¯æ¬¡è¯·æ±‚ä¹‹å‰è¿›è¡Œä»£ç†ä¿®æ­£</span><br><span class="line">          if request.url.split(&#x27;:&#x27;)[0] == &#x27;http&#x27;:</span><br><span class="line">              request.meta[&#x27;proxy&#x27;] = &#x27;http://&#x27; + random.choice(PROXY_http)</span><br><span class="line">          else:</span><br><span class="line">              request.meta[&#x27;proxy&#x27;] = &#x27;http://&#x27; + random.choice(PROXY_https)</span><br><span class="line">          return None</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ul>
</li>
<li><p>æ‹¦æˆªå“åº”</p>
<ul>
<li>ç¯¡æ”¹å“åº”å¯¹è±¡æˆ–ç›´æ¥æ›¿æ¢å“åº”å¯¹è±¡</li>
</ul>
</li>
</ol>
</li>
<li><p>ä¸‹è½½ä¸­é—´ä»¶ </p>
<ol>
<li><p>```python<br> import scrapy<br> from selenium.webdriver import Chrome,ChromeOptions<br> from selenium.webdriver.chrome.options import Options<br> from wangyi.items import WangyiItem</p>
<h1 id="åˆ›å»ºoptionså®ä¾‹å¯¹è±¡-å®ç°æ— å¤´æµè§ˆå™¨"><a href="#åˆ›å»ºoptionså®ä¾‹å¯¹è±¡-å®ç°æ— å¤´æµè§ˆå™¨" class="headerlink" title="åˆ›å»ºoptionså®ä¾‹å¯¹è±¡,å®ç°æ— å¤´æµè§ˆå™¨"></a>åˆ›å»ºoptionså®ä¾‹å¯¹è±¡,å®ç°æ— å¤´æµè§ˆå™¨</h1><p> chrome_option = Options()<br> chrome_option.add_argument(â€˜â€“headlessâ€™)<br> chrome_option.add_argument(â€˜â€“disable-gpuâ€™)<br> class WangyiSpider(scrapy.Spider):</p>
<pre><code> name = &#39;wangyi&#39;
 # allowed_domains = [&#39;www.xxx.com&#39;]
 # åŸå§‹urlç½‘é¡µ
 start_urls = [&#39;https://news.163.com/&#39;]
 pro = Chrome(chrome_options=chrome_option)
 # ç”¨æ¥å­˜å‚¨åç»­çš„æ‰€æœ‰å­é¡µé¢çš„url
 cls_url_list = []

 def parse(self, response):
     # å‡†å¤‡è¦çˆ¬å–çš„ç›®æ ‡
     index_list = [3,4]
     li_list = response.xpath(&#39;//*[@id=&quot;index2016_wrap&quot;]/div[1]/div[2]/div[2]/div[2]/div[2]/div/ul/li&#39;)
     # print(li_list)
     for index in index_list:
         li = li_list[index]
         # è·å–å­é¡µé¢url
         new_url = li.xpath(&#39;./a/@href&#39;).extract_first()
         # è·å–ç‹¬å½±çš„åˆ†ç±»åç§°
         news = li.xpath(&#39;./a/text()&#39;).extract_first()
         # å°†å­é¡µé¢çš„urlæ·»åŠ åˆ°ç±»å±æ€§ä¸­è¿›è¡Œå­˜å‚¨
         self.cls_url_list.append(new_url)
         # å¼€å§‹å¯¹å­é¡µé¢è¿›è¡Œè¿‡è¯·æ±‚,å¹¶å°†è¯·æ±‚æ•°æ®äº¤ç»™ä¸‹ä¸€ä¸ªè§£æå‡½æ•°
         yield scrapy.Request(url=new_url,callback=self.new_prase)
 
 def new_prase(self,response):
     div_list = response.xpath(&#39;/html/body/div/div[3]/div[4]/div[1]/div/div/ul/li/div/div&#39;)
     for div in div_list:
         # è·å¾—æ–°é—»æ ‡é¢˜ä¸æ–°é—»è¯¦æƒ…é¡µé¢çš„url
         title = div.xpath(&#39;./div/div/h3/a/text()&#39;).extract_first()
         new_url = div.xpath(&#39;./div/div/h3/a/@href&#39;).extract_first()
         # åˆ›å»ºitemå¯¹è±¡,å¹¶å°†åé¢ä¼šç”¨åˆ°çš„æ ‡é¢˜å­˜å‚¨è¿›å»
         item = WangyiItem()
         item[&#39;title&#39;] = title
         # å¼€å§‹å¯¹è¯¦æƒ…é¡µé¢è¿›è¡Œè¯·æ±‚,å¹¶å°†è·å–åˆ°çš„é¡µé¢æºç ä¸itemå¯¹è±¡ä¸€èµ·ä¼ é€’ç»™ä¸‹ä¸€ä¸ªè§£æå‡½æ•°
         yield scrapy.Request(url=new_url,callback=self.content_parse,meta=&#123;&#39;item&#39;: item&#125;)
 def content_parse(self,response):
     # æŠ½å–ä¼ é€’è¿‡æ¥çš„itemå¯¹è±¡
     item = response.meta[&#39;item&#39;]
     # è§£ææºç ä¸­çš„å†…å®¹æ•°æ®
     content = response.xpath(&#39;//*[@id=&quot;endText&quot;]/p/text()&#39;).extract()
     # å°†å†…å®¹å­˜å‚¨è¿›itemå¯¹è±¡
     item[&#39;content&#39;] = &#39;&#39;.join(content)
     # å°†æ•°æ®æäº¤ç»™ç®¡é“
     yield item

 def closed(self,spider):
     # å½“çˆ¬è™«ç»“æŸæ—¶,å…³é—­seleniumæµè§ˆå™¨
     self.pro.quit()
</code></pre>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">    ä»¥ä¸Šä¸ºçˆ¬è™«æ–‡ä»¶ä¸­çš„æ„é€ </span><br><span class="line"></span><br><span class="line">2. ```python</span><br><span class="line">    class WangyiPipeline(object):</span><br><span class="line">        # åœ¨çˆ¬è™«å¼€å§‹è¿è¡Œæ—¶è¿›è¡Œæ–‡ä»¶çš„åˆ›å»º</span><br><span class="line">        def open_spider(self, spider):</span><br><span class="line">            self.fp = open(&#x27;./news.txt&#x27;, &#x27;w&#x27;, encoding=&#x27;utf-8&#x27;)</span><br><span class="line">    </span><br><span class="line">    	# å¯¹æäº¤çš„itemæ•°æ®è¿›è¡Œå¤„ç†</span><br><span class="line">        def process_item(self, item, spider):</span><br><span class="line">            title = item[&#x27;title&#x27;]</span><br><span class="line">            content = item[&#x27;content&#x27;]</span><br><span class="line">            # print(item)</span><br><span class="line">            # å°†itemæ•°æ®è¿›è¡Œå­˜å‚¨</span><br><span class="line">            self.fp.write(&#x27;[&#x27; + &#x27;title&#x27; + &#x27;:&#x27; + title + &#x27;,&#x27; + &#x27;content&#x27; + &#x27;:&#x27; + content + &#x27;]&#x27; + &#x27;\n&#x27;)</span><br><span class="line">            return item</span><br><span class="line">        def close_spider(self, spider):</span><br><span class="line">            # çˆ¬è™«ç»“æŸæ—¶,å…³é—­æ‰“å¼€çš„æ–‡ä»¶</span><br><span class="line">            self.fp.close()</span><br></pre></td></tr></table></figure>

<p> ä»¥ä¸Šä¸ºç®¡é“ä¸­çš„ä»£ç </p>
</li>
<li><p>```python<br> from scrapy import signals<br> from scrapy.http import HtmlResponse<br> from time import sleep<br> class WangyiDownloaderMiddleware(object):</p>
<pre><code> # æ•è·å“åº”æ•°æ®å¹¶è¿›è¡Œæ£€æµ‹
 def process_response(self, request, response, spider):
     # æŠ½å–çˆ¬è™«æ–‡ä»¶ä¸­çš„æ¨¡æ‹Ÿæµè§ˆå™¨
     pro = spider.pro
     # å¯¹è¯·æ±‚å¯¹è±¡è¿›è¡Œè§£æ,å½“å¯¹è±¡ä¸ºä¸»é¡µé¢çš„æ—¶å€™,æ— è§†
     # spiderå‚æ•°ä¸ºå®ä¾‹åŒ–çš„çˆ¬è™«ç±»
     # å¯ä»¥ç›´æ¥è°ƒç”¨çˆ¬è™«ç±»çš„ä¸€äº›æ–¹æ³•
     if request.url in spider.cls_url_list:
         # é€šè¿‡æ¨¡æ‹Ÿæµè§ˆå™¨å‘èµ·è¯·æ±‚,ç»•å¼€åŠ¨æ€åŠ è½½
         pro.get(request.url)
         # ç­‰å¾…ä¸€ç§’,ç¡®ä¿æ•°æ®åŠ è½½å®Œæˆ
         sleep(1)
         # è·å–é¡µé¢æºç 
         page_text = pro.page_source
         # å®ä¾‹åŒ–HtmlResponseå¯¹è±¡
         # url    è¯·æ±‚çš„urlå¯¹è±¡
         # body   è¦è¿”å›çš„é¡µé¢æºç æ•°æ®
         # encoding  è®¾å®šé¡µé¢æºç çš„ç¼–ç æ ¼å¼
         # request   è¯·æ±‚ä¸å˜
         new_response = HtmlResponse(url=request.url,body=page_text,encoding=&#39;utf-8&#39;,request=request)
         # å°†å‡†å¤‡å¥½çš„æ•°æ®è¿”å›
         return new_response
     return response
</code></pre>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">       ä»¥ä¸Šä¸ºä¸­é—´ä»¶ä¸­çš„æ•°æ®</span><br><span class="line"></span><br><span class="line">   4. åœ¨è¿™ä¸‰ç§æ¨¡å—çš„è¾…åŠ©ä¹‹ä¸‹,å¯ä»¥å®ç°å¯¹ç½‘ç«™æ•°æ®çš„æ·±åº¦çˆ¬å–,å¿…è¦æ—¶,å¯ä»¥æ·»åŠ é¡µç æ•°æ®,ä»è€Œç¡®ä¿è¿™ä¸ªçˆ¬è™«å¯ä»¥ç²¾ç¡®å®šä½åˆ°æ¯ä¸€ä¸ªåˆ†ç±»ä¸‹çš„æ‰€æœ‰æ•°æ®çš„æ¯ä¸€é¡µæ•°æ®,ä¹Ÿå°±æ˜¯è¯´,ä½¿ç”¨scrapyçˆ¬è™«,å¯ä»¥ç›´æ¥å®ç°å¯¹æ•´ä¸ªç›®æ ‡ç½‘ç«™çš„è¦†ç›–æ€§çˆ¬å–æ•°æ®</span><br><span class="line"></span><br><span class="line">   5. åŒæ—¶,ç”±äºscrapyé»˜è®¤æ˜¯å¼‚æ­¥è¿è¡Œçš„,è¿™ç§å½¢æ€çš„çˆ¬è™«,å·¥ä½œæ•ˆç‡æ¯”èµ·requestsè¦é«˜å¾—å¤š</span><br><span class="line"></span><br><span class="line">3. ### UserAgentä¼ªè£…</span><br><span class="line"></span><br><span class="line">   1. ```python</span><br><span class="line">      from fake_useragent import UserAgent</span><br><span class="line">      a = UserAgent()</span><br><span class="line">      print(a.Chrome)</span><br></pre></td></tr></table></figure></li>
</ol>
</li>
</ol>
</div><div class="article-licensing box"><div class="licensing-title"><p>Scraypè¯¦è§£</p><p><a href="http://sokrates.com.cn/2022/11/30/Study-notes-Python-Spider-scrapyè¯¦è§£/">http://sokrates.com.cn/2022/11/30/Study-notes-Python-Spider-scrapyè¯¦è§£/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>ä½œè€…</h6><p>Kawakami Ari</p></div></div><div class="level-item is-narrow"><div><h6>å‘å¸ƒäº</h6><p>2022-11-30</p></div></div><div class="level-item is-narrow"><div><h6>æ›´æ–°äº</h6><p>2022-11-29</p></div></div><div class="level-item is-narrow"><div><h6>è®¸å¯åè®®</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/Python/">Python</a><a class="link-muted mr-2" rel="tag" href="/tags/Spider/">Spider</a></div><div class="sharethis-inline-share-buttons"></div><script src="https://ppoffice.github.io/hexo-theme-icarus/categories/Plugins/Share/" defer></script></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered">å–œæ¬¢è¿™ç¯‡æ–‡ç« ï¼Ÿæ‰“èµä¸€ä¸‹ä½œè€…å§</h3><div class="buttons is-centered"><a class="button donate" data-type="alipay"><span class="icon is-small"><i class="fab fa-alipay"></i></span><span>æ”¯ä»˜å®</span><span class="qrcode"><img src="/img/alipay.png" alt="æ”¯ä»˜å®"></span></a><a class="button donate" data-type="paypal" onclick="document.getElementById(&#039;paypal-donate-form&#039;).submit()"><span class="icon is-small"><i class="fab fa-paypal"></i></span><span>Paypal</span></a><form action="https://www.paypal.com/cgi-bin/webscr" method="post" target="_blank" rel="noopener" id="paypal-donate-form"><input type="hidden" name="cmd" value="_donations"><input type="hidden" name="business" value="kawakami-araki@foxmail.com"><input type="hidden" name="currency_code" value="USD"></form><a class="button donate" data-type="wechat"><span class="icon is-small"><i class="fab fa-weixin"></i></span><span>å¾®ä¿¡</span><span class="qrcode"><img src="/img/weixin.png" alt="å¾®ä¿¡"></span></a></div></div></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2022/11/30/Study-notes-Python-Spider-requests%E8%AF%B7%E6%B1%82%E6%A8%A1%E5%9D%97%E8%AF%A6%E8%A7%A3/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">requestsè¯·æ±‚æ¨¡å—è¯¦è§£</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2022/11/30/Study-notes-Python-Spider-redis%E6%A6%82%E8%A7%88/"><span class="level-item">redisæ¦‚è§ˆ</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><!--!--></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="/img/author.jpg" alt="Kawakami Ari"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Kawakami Ari</p><p class="is-size-6 is-block">Otaku</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>China</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">æ–‡ç« </p><a href="/archives"><p class="title">95</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">åˆ†ç±»</p><a href="/categories"><p class="title">12</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">æ ‡ç­¾</p><a href="/tags"><p class="title">33</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/kawakami-araki/" target="_blank" rel="noopener">å…³æ³¨æˆ‘</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/kawakami-araki"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Dribbble" href="https://dribbble.com"><i class="fab fa-dribbble"></i></a></div></div></div><!--!--><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">åˆ†ç±»</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/C/"><span class="level-start"><span class="level-item">C++</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/categories/Django/"><span class="level-start"><span class="level-item">Django</span></span><span class="level-end"><span class="level-item tag">21</span></span></a></li><li><a class="level is-mobile" href="/categories/Django-DRF/"><span class="level-start"><span class="level-item">Django DRF</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/Hexo/"><span class="level-start"><span class="level-item">Hexo</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/JavaScript/"><span class="level-start"><span class="level-item">JavaScript</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/"><span class="level-start"><span class="level-item">Python</span></span><span class="level-end"><span class="level-item tag">40</span></span></a></li><li><a class="level is-mobile" href="/categories/VTD/"><span class="level-start"><span class="level-item">VTD</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/scala/"><span class="level-start"><span class="level-item">scala</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%97%A5%E5%B8%B8/"><span class="level-start"><span class="level-item">æ—¥å¸¸</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%B0%B8%E5%8A%AB%E6%97%A0%E9%97%B4%E8%8B%B1%E9%9B%84%E8%AE%BE%E8%AE%A1%E6%B4%BB%E5%8A%A8/"><span class="level-start"><span class="level-item">æ°¸åŠ«æ— é—´è‹±é›„è®¾è®¡æ´»åŠ¨</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%8D%89%E7%A8%BF%E7%AE%B1/"><span class="level-start"><span class="level-item">è‰ç¨¿ç®±</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BE%E8%AE%A1%E7%A8%BF/"><span class="level-start"><span class="level-item">è®¾è®¡ç¨¿</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">æ ‡ç­¾</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/Big-Data/"><span class="tag">Big Data</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/C/"><span class="tag">C++</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DRF/"><span class="tag">DRF</span><span class="tag">8</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Django/"><span class="tag">Django</span><span class="tag">29</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Flask/"><span class="tag">Flask</span><span class="tag">16</span></a></div><div class="control"><a class="tags has-addons" href="/tags/GIT/"><span class="tag">GIT</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/JavaScript/"><span class="tag">JavaScript</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/LOL/"><span class="tag">LOL</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/MD5/"><span class="tag">MD5</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/MongoDB/"><span class="tag">MongoDB</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Numpy/"><span class="tag">Numpy</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ORM/"><span class="tag">ORM</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Pandas/"><span class="tag">Pandas</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Python/"><span class="tag">Python</span><span class="tag">68</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Redis/"><span class="tag">Redis</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Scala/"><span class="tag">Scala</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Spark/"><span class="tag">Spark</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Spider/"><span class="tag">Spider</span><span class="tag">16</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Vue/"><span class="tag">Vue</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Warframe/"><span class="tag">Warframe</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ajax/"><span class="tag">ajax</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/matplotlib/"><span class="tag">matplotlib</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%9F%BA%E7%A1%80/"><span class="tag">åŸºç¡€</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%B9%BB%E6%83%B3/"><span class="tag">å¹»æƒ³</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%8A%80%E6%9C%AF/"><span class="tag">æŠ€æœ¯</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%95%99%E7%A8%8B/"><span class="tag">æ•™ç¨‹</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%98%9F%E9%99%85%E6%88%98%E7%94%B2/"><span class="tag">æ˜Ÿé™…æˆ˜ç”²</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%B0%B8%E5%8A%AB%E6%97%A0%E9%97%B4/"><span class="tag">æ°¸åŠ«æ— é—´</span><span class="tag">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%B8%B8%E6%88%8F/"><span class="tag">æ¸¸æˆ</span><span class="tag">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%81%B5%E6%84%9F/"><span class="tag">çµæ„Ÿ</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%B7%A8%E5%9F%9F/"><span class="tag">è·¨åŸŸ</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%BD%A6%E4%B8%87/"><span class="tag">è½¦ä¸‡</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E9%9A%8F%E7%AC%94/"><span class="tag">éšç¬”</span><span class="tag">2</span></a></div></div></div></div></div><div class="column-right-shadow is-hidden-widescreen is-sticky"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3 is-sticky"><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">é“¾æ¥</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://hexo.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Hexo</span></span><span class="level-right"><span class="level-item tag">hexo.io</span></span></a></li><li><a class="level is-mobile" href="https://blog.csdn.net/weixin_45707730?spm=1000.2115.3001.5343" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Tyt</span></span><span class="level-right"><span class="level-item tag">blog.csdn.net</span></span></a></li></ul></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">æœ€æ–°æ–‡ç« </h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-11-30T15:10:51.393Z">2022-11-30</time></p><p class="title"><a href="/2022/11/30/Study-notes-VTD-VTD%E8%B7%AF%E7%BD%91%E7%BC%96%E8%BE%91%E5%99%A8/">VTDè·¯ç½‘ç¼–è¾‘å™¨ç›¸å…³</a></p><p class="categories"><a href="/categories/VTD/">VTD</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-11-30T15:10:51.393Z">2022-11-30</time></p><p class="title"><a href="/2022/11/30/Study-notes-VTD-VTD%E5%AE%89%E8%A3%85/">VTD(Virtual Test Drive)ç›¸å…³å®‰è£…æµç¨‹ä»¥åŠæ³¨æ„äº‹é¡¹</a></p><p class="categories"><a href="/categories/VTD/">VTD</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-11-30T15:10:51.391Z">2022-11-30</time></p><p class="title"><a href="/2022/11/30/Study-notes-spark%E9%A1%B9%E7%9B%AE%E7%9B%B8%E5%85%B3%E6%B3%A8%E9%87%8A/">å…³äºä¸€ä¸ªsparké¡¹ç›®çš„è¯¦ç»†æ‹†åˆ†è§£æ</a></p><p class="categories"><a href="/categories/scala/">scala</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-11-30T15:10:51.390Z">2022-11-30</time></p><p class="title"><a href="/2022/11/30/Study-notes-Python-Spider-%E8%BF%9B%E7%A8%8B%E7%BA%BF%E7%A8%8B%E4%B8%8E%E5%8D%8F%E7%A8%8B/">è¿›ç¨‹çº¿ç¨‹åç¨‹ä¸çˆ¬è™«</a></p><p class="categories"><a href="/categories/Python/">Python</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-11-30T15:10:51.389Z">2022-11-30</time></p><p class="title"><a href="/2022/11/30/Study-notes-Python-Spider-%E7%A7%BB%E5%8A%A8%E7%AB%AF%E6%95%B0%E6%8D%AE%E7%88%AC%E5%8F%96%E4%B8%8E%E8%A7%A3%E6%9E%90/">ç§»åŠ¨ç«¯æ•°æ®çˆ¬å–</a></p><p class="categories"><a href="/categories/Python/">Python</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">å½’æ¡£</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2022/11/"><span class="level-start"><span class="level-item">åä¸€æœˆ 2022</span></span><span class="level-end"><span class="level-item tag">95</span></span></a></li></ul></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.png" alt="Chevalier de bronze" height="28"></a><p class="is-size-7"><span>&copy; 2022 Kawakami Ari</span>Â Â Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>Â &amp;Â <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("zh-CN");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="å›åˆ°é¡¶ç«¯" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "æ­¤ç½‘ç«™ä½¿ç”¨Cookieæ¥æ”¹å–„æ‚¨çš„ä½“éªŒã€‚",
          dismiss: "çŸ¥é“äº†ï¼",
          allow: "å…è®¸ä½¿ç”¨Cookie",
          deny: "æ‹’ç»",
          link: "äº†è§£æ›´å¤š",
          policy: "Cookieæ”¿ç­–",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="æƒ³è¦æŸ¥æ‰¾ä»€ä¹ˆ..."></div><a class="searchbox-close" href="javascript:;">Ã—</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"æƒ³è¦æŸ¥æ‰¾ä»€ä¹ˆ...","untitled":"(æ— æ ‡é¢˜)","posts":"æ–‡ç« ","pages":"é¡µé¢","categories":"åˆ†ç±»","tags":"æ ‡ç­¾"});
        });</script></body></html>